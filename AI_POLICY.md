# AI Usage Policy
**Effective Date**: [Insert Effective Date, e.g., 2026-02-28]  
**Applicable To**: All contributors, maintainers, and individuals submitting content to this project.

## 1. Purpose
This policy outlines the guidelines for the use of Artificial Intelligence (AI) tools—including but not limited to code assistants, generative AI models, large language models (LLMs), and AI-powered coding editors—in contributions to this project. Its core objectives are to:
- Ensure the quality, security, and maintainability of code and documentation.
- Clarify the copyright and responsibility boundaries of AI-generated content.
- Maintain transparency in open-source collaboration.
- Comply with the terms of the project’s open-source license (e.g., MIT, Apache 2.0, GPL).

## 2. Scope
This policy applies to all:
- Contributors, maintainers, and users submitting content to the project.
- Forms of contributions, including code, documentation, pull requests (PRs), commits, issues, and comments.
- AI tools used during the development or contribution process (e.g., GitHub Copilot, ChatGPT, Claude, Gemini, CodeLlama, Cursor).

## 3. Permitted Uses
AI tools may be used to assist with the following tasks, provided that all AI-generated output is reviewed, verified, and edited by a human before submission:
- Code completion, syntax correction, and code refactoring suggestions.
- Drafting, editing, or translating documentation, comments, and examples.
- Generating test cases (which must be manually validated for effectiveness).
- Assisting with problem debugging, technical research, and idea brainstorming.
- Simplifying repetitive code or generating common utility functions.

## 4. Prohibited Uses
The following uses of AI tools are strictly prohibited:
- Submitting fully AI-generated content (code, documentation, etc.) without meaningful human review, modification, or validation.
- Using AI to generate code, text, or other content that violates copyright laws, third-party licenses, or intellectual property rights.
- Generating vulnerable, malicious, obfuscated, or otherwise unsafe code using AI.
- Concealing or failing to disclose the use of AI in any contribution.
- Using AI to bypass code quality standards, security checks, or project guidelines.

## 5. Transparency & Disclosure
If AI was used to assist with any part of your contribution, you must:
- Include a clear disclosure in your PR description or commit message. Examples of acceptable disclosure:
  - `AI-assisted: This code was generated with AI and reviewed/edited by a human.`
  - `AI help used for documentation drafting; manually verified for accuracy.`
- Never represent AI-generated content as entirely human-created.

## 6. Responsibility
- All contributors are fully responsible for the accuracy, quality, security, and compliance of all content they submit—including content assisted by AI.
- Project maintainers are not liable for errors, bugs, security vulnerabilities, or legal risks arising from the improper use of AI tools by contributors.
- Maintainers reserve the right to reject any contribution that violates this policy, request modifications, or restrict contribution privileges for repeated violations.

## 7. Licensing & Copyright
- All contributions (including AI-assisted content) must comply with the project’s open-source license and all applicable laws.
- Do not submit AI-generated content that incorporates proprietary, confidential, or license-incompatible material.
- Ensure that AI tools used do not violate the terms of service of the tool provider or infringe on third-party intellectual property.

## 8. Policy Updates
This policy may be updated from time to time to adapt to changes in AI technology, open-source best practices, or project needs. Continued contribution to the project implies acceptance of the latest version of this policy.

---
*Last Updated: [2026-02-28]*